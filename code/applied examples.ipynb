{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a72767b9",
   "metadata": {},
   "source": [
    "# ABC's of M-estimation\n",
    "\n",
    "Code for applied examples (Section 2)\n",
    "\n",
    "Paul Zivich (2023/04/04)\n",
    "\n",
    "## Loading dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9ebf7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versions\n",
      "NumPy:         1.22.2\n",
      "Pandas:        1.4.1\n",
      "SciPy:         1.9.2\n",
      "Statsmodels:   0.13.2\n",
      "Delicatessen:  1.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy.optimize import root\n",
    "from scipy.optimize import approx_fprime\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import delicatessen as deli\n",
    "from delicatessen import MEstimator\n",
    "from delicatessen.estimating_equations import ee_regression\n",
    "from delicatessen.utilities import inverse_logit\n",
    "\n",
    "\n",
    "print(\"versions\")\n",
    "print('NumPy:        ', np.__version__)\n",
    "print('Pandas:       ', pd.__version__)\n",
    "print('SciPy:        ', sp.__version__)\n",
    "print('Statsmodels:  ', sm.__version__)\n",
    "print('Delicatessen: ', deli.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637bb4c2",
   "metadata": {},
   "source": [
    "## Example 1: Logistic Regression\n",
    "\n",
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac7d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame()\n",
    "d['X'] = [0, 0, 0, 0, 1, 1, 1, 1]\n",
    "d['W'] = [0, 0, 1, 1, 0, 0, 1, 1]\n",
    "d['Y'] = [0, 1, 0, 1, 0, 1, 0, 1]\n",
    "d['n'] = [496, 74, 113, 25, 85, 15, 15, 3]\n",
    "d['intercept'] = 1\n",
    "d = pd.DataFrame(np.repeat(d.values, d['n'], axis=0),   # Expanding compact data frame\n",
    "                 columns=d.columns)                     # ... keeping column names\n",
    "d = d[['intercept', 'X', 'W', 'Y']].copy()              # Dropping the n column\n",
    "n = d.shape[0]                                          # Number of observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5d6f57",
   "metadata": {},
   "source": [
    "### Regression by MLE\n",
    "\n",
    "Using `statsmodels` GLM functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b112c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "fam = sm.families.Binomial()           # Binomial family\n",
    "mle = smf.glm(\"Y ~ X + W\",             # GLM with formula\n",
    "              data=d,                  # ... for loaded data\n",
    "              family=fam               # ... logistic model\n",
    "              ).fit()                  # ... then fitting model\n",
    "beta_mle = np.asarray(mle.params)      # Extracting beta parameters\n",
    "sigma_mle = np.asarray(mle.bse**2)     # Extracting variance estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f5174b",
   "metadata": {},
   "source": [
    "### M-estimator by-hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b476c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimating_functions(theta):\n",
    "    # Calculating predicted probability of Y\n",
    "    yhat = inverse_logit(theta[0]*1 + theta[1]*d['X'] + theta[2]*d['W'])\n",
    "\n",
    "    # Calculating the residual (observed Y minus predicted Y)\n",
    "    residual = d['Y'] - yhat\n",
    "\n",
    "    # Calculating the corresponding score functions\n",
    "    score = [residual*1,         # Score for intercept\n",
    "             residual*d['X'],    # Score for X\n",
    "             residual*d['W']]    # Score for W\n",
    "\n",
    "    # Returning scores as a NumPy array\n",
    "    return np.asarray(score)\n",
    "\n",
    "\n",
    "def estimating_equations(theta):\n",
    "    ef = estimating_functions(theta=theta)\n",
    "    vals = ()                    # Create empty tuple\n",
    "    rows = ef.shape[0]           # Determine how many rows / parameters are present\n",
    "    for i in range(rows):        # Go through each individual theta in the stack\n",
    "        row = ef[i, :]           # ... extract corresponding row\n",
    "        vals += (np.sum(row), )  # ... then add the theta sum to the tuple of thetas\n",
    "    # Return evaluated estimating equations\n",
    "    return np.asarray(vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8d432e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root-finding\n",
    "proc = root(estimating_equations,       # Function to find root(s) of\n",
    "            x0=np.array([0, 0, 0, ]),   # ... starting values for root-finding procedure\n",
    "            method='lm')                # ... algorithm to use (Levenberg-Marquardt here)\n",
    "beta_mest = proc.x                      # Extract beta parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b74d0ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baking the bread (approximate derivative)\n",
    "deriv = approx_fprime(xk=beta_mest,             # Approximating partial derivatives at beta\n",
    "                      f=estimating_equations,   # ... of the estimating equations\n",
    "                      epsilon=1e-9)             # ... with specified deviation from point\n",
    "bread = -1*deriv / n                            # Creating bread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4694dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cooking the filling (matrix algebra)\n",
    "filling = np.dot(estimating_functions(beta_mest),\n",
    "                 estimating_functions(beta_mest).T)\n",
    "filling = filling / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8f1d9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembling the sandwich (matrix algebra)\n",
    "bread_invert = np.linalg.inv(bread)\n",
    "sandwich = np.dot(np.dot(bread_invert, filling),\n",
    "                  bread_invert.T) / n\n",
    "sigma_mest = np.diag(sandwich)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965ae2d1",
   "metadata": {},
   "source": [
    "### Using `delicatessen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2d631e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(theta):\n",
    "    # Using built-in regression model functionality from delicatessen\n",
    "    return ee_regression(theta=theta,\n",
    "                         y=d['Y'],\n",
    "                         X=d[['intercept', 'X', 'W']],\n",
    "                         model='logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eef896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mestr = MEstimator(psi, init=[0, 0, 0])\n",
    "mestr.estimate(solver='lm')\n",
    "\n",
    "beta_deli = mestr.theta\n",
    "sigma_deli = np.diag(mestr.variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5617c86c",
   "metadata": {},
   "source": [
    "### Comparing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bb4e393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Logistic Regression\n",
      "Point Estimates\n",
      "MLE:          [-1.89450082  0.11873535  0.36051133]\n",
      "By-hand:      [-1.89450082  0.11873535  0.36051133]\n",
      "Delicatessen: [-1.89450082  0.11873535  0.36051133]\n",
      "Variance Estimates\n",
      "MLE:          [0.01496046 0.07764837 0.05660453]\n",
      "By-hand:      [0.01484041 0.0777204  0.05652963]\n",
      "Delicatessen: [0.01484041 0.0777204  0.05652963]\n"
     ]
    }
   ],
   "source": [
    "print(\"1: Logistic Regression\")\n",
    "print(\"Point Estimates\")\n",
    "print(\"MLE:         \", beta_mle)\n",
    "print(\"By-hand:     \", beta_mest)\n",
    "print(\"Delicatessen:\", beta_deli)\n",
    "\n",
    "print(\"Variance Estimates\")\n",
    "print(\"MLE:         \", sigma_mle)\n",
    "print(\"By-hand:     \", sigma_mest)\n",
    "print(\"Delicatessen:\", sigma_deli)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b599362",
   "metadata": {},
   "source": [
    "## Example 2a: Standardization by g-computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13b94509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copies of data with policies applied\n",
    "d1 = d.copy()\n",
    "d1['X'] = 1\n",
    "d0 = d.copy()\n",
    "d0['X'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c670aa",
   "metadata": {},
   "source": [
    "### Using `delicatessen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6370cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(theta):\n",
    "    # Dividing parameters into corresponding parts and labels from slides\n",
    "    beta = theta[0:3]                     # Logistic model coefficients\n",
    "    mu1, mu0 = theta[3], theta[4]         # Causal risks\n",
    "    delta1, delta2 = theta[5], theta[6]   # Causal contrasts\n",
    "\n",
    "    # Using built-in regression model functionality from delicatessen\n",
    "    ee_logit = ee_regression(theta=beta,\n",
    "                             y=d['Y'],\n",
    "                             X=d[['intercept', 'X', 'W']],\n",
    "                             model='logistic')\n",
    "\n",
    "    # Transforming logistic model coefficients into causal parameters\n",
    "    y1_hat = inverse_logit(np.dot(d1[['intercept', 'X', 'W']], beta))  # Prediction under a=1\n",
    "    y0_hat = inverse_logit(np.dot(d0[['intercept', 'X', 'W']], beta))  # Prediction under a=0\n",
    "    # Estimating function for causal risk under a=1\n",
    "    ee_r1 = y1_hat - mu1\n",
    "    # Estimating function for causal risk under a=0\n",
    "    ee_r0 = y0_hat - mu0\n",
    "    # Estimating function for causal risk difference\n",
    "    ee_rd = np.ones(d.shape[0])*((mu1 - mu0) - delta1)\n",
    "    # Estimating function for causal risk ratio\n",
    "    ee_rr = np.ones(d.shape[0])*(np.log(mu1 / mu0) - delta2)\n",
    "\n",
    "    # Returning stacked estimating functions in order of parameters\n",
    "    return np.vstack([ee_logit,   # EF of logistic model\n",
    "                      ee_r1,      # EF of causal risk a=1\n",
    "                      ee_r0,      # EF of causal risk a=0\n",
    "                      ee_rd,      # EF of causal risk difference\n",
    "                      ee_rr])     # EF of causal log risk ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4eea8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mestr = MEstimator(psi, init=[0, 0, 0, 0.5, 0.5, 0, 0])\n",
    "mestr.estimate(solver='lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bccea801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2a: Causal parameters -- g-computation\n",
      "Risk 1:          0.154\n",
      "95% CI:          [0.089 0.22 ]\n",
      "Risk 0:          0.14\n",
      "95% CI:          [0.114 0.165]\n",
      "Risk Difference: 0.015\n",
      "95% CI:          [-0.055  0.085]\n",
      "Risk Ratio:      1.106\n",
      "95% CI:          [0.697 1.756]\n"
     ]
    }
   ],
   "source": [
    "print(\"2a: Causal parameters -- g-computation\")\n",
    "print(\"Risk 1:         \", np.round(mestr.theta[3], 3))\n",
    "print(\"95% CI:         \", np.round(mestr.confidence_intervals()[3, :], 3))\n",
    "print(\"Risk 0:         \", np.round(mestr.theta[4], 3))\n",
    "print(\"95% CI:         \", np.round(mestr.confidence_intervals()[4, :], 3))\n",
    "print(\"Risk Difference:\", np.round(mestr.theta[5], 3))\n",
    "print(\"95% CI:         \", np.round(mestr.confidence_intervals()[5, :], 3))\n",
    "print(\"Risk Ratio:     \", np.round(np.exp(mestr.theta[6]), 3))\n",
    "print(\"95% CI:         \", np.round(np.exp(mestr.confidence_intervals()[6, :]), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448dab37",
   "metadata": {},
   "source": [
    "## Example 2b: Standardization by IPW\n",
    "\n",
    "### Using `delicatessen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7e63e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(theta):\n",
    "    # Dividing parameters into corresponding parts and labels from slides\n",
    "    alpha = theta[0:2]                    # Logistic model coefficients\n",
    "    mu1, mu0 = theta[2], theta[3]         # Causal risks\n",
    "    delta1, delta2 = theta[4], theta[5]   # Causal contrasts\n",
    "\n",
    "    # Using built-in regression model functionality from delicatessen\n",
    "    ee_logit = ee_regression(theta=alpha,\n",
    "                             y=d['X'],\n",
    "                             X=d[['intercept', 'W']],\n",
    "                             model='logistic')\n",
    "\n",
    "    # Transforming logistic model coefficients into causal parameters\n",
    "    pscore = inverse_logit(np.dot(d1[['intercept', 'W']], alpha))  # Propensity score\n",
    "    wt = d['X']/pscore + (1-d['X'])/(1-pscore)                     # Corresponding weights\n",
    "    # Estimating function for causal risk under a=1\n",
    "    ee_r1 = d['X']*d['Y']*wt - mu1\n",
    "    # Estimating function for causal risk under a=0\n",
    "    ee_r0 = (1-d['X'])*d['Y']*wt - mu0\n",
    "    # Estimating function for causal risk difference\n",
    "    ee_rd = np.ones(d.shape[0])*((mu1 - mu0) - delta1)\n",
    "    # Estimating function for causal risk ratio\n",
    "    ee_rr = np.ones(d.shape[0])*(np.log(mu1 / mu0) - delta2)\n",
    "\n",
    "    # Returning stacked estimating functions in order of parameters\n",
    "    return np.vstack([ee_logit,   # EF of logistic model\n",
    "                      ee_r1,      # EF of causal risk a=1\n",
    "                      ee_r0,      # EF of causal risk a=0\n",
    "                      ee_rd,      # EF of causal risk difference\n",
    "                      ee_rr])     # EF of causal log risk ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d050716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mestr = MEstimator(psi, init=[0, 0, 0.5, 0.5, 0, 0])\n",
    "mestr.estimate(solver='lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "865a10e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2b: Causal parameters -- IPW\n",
      "Risk 1:          0.153\n",
      "95% CI:          [0.088 0.219]\n",
      "Risk 0:          0.14\n",
      "95% CI:          [0.114 0.165]\n",
      "Risk Difference: 0.014\n",
      "95% CI:          [-0.057  0.084]\n",
      "Risk Ratio:      1.098\n",
      "95% CI:          [0.69  1.747]\n"
     ]
    }
   ],
   "source": [
    "print(\"2b: Causal parameters -- IPW\")\n",
    "print(\"Risk 1:         \", np.round(mestr.theta[2], 3))\n",
    "print(\"95% CI:         \", np.round(mestr.confidence_intervals()[2, :], 3))\n",
    "print(\"Risk 0:         \", np.round(mestr.theta[3], 3))\n",
    "print(\"95% CI:         \", np.round(mestr.confidence_intervals()[3, :], 3))\n",
    "print(\"Risk Difference:\", np.round(mestr.theta[4], 3))\n",
    "print(\"95% CI:         \", np.round(mestr.confidence_intervals()[4, :], 3))\n",
    "print(\"Risk Ratio:     \", np.round(np.exp(mestr.theta[5]), 3))\n",
    "print(\"95% CI:         \", np.round(np.exp(mestr.confidence_intervals()[5, :]), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f167b3c4",
   "metadata": {},
   "source": [
    "## Example 3: Data Fusion\n",
    "\n",
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f1f5e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame()\n",
    "d['R'] = [1, 1, 0, 0, 0, 0]\n",
    "d['Y'] = [0, 0, 1, 1, 0, 0]\n",
    "d['W'] = [1, 0, 1, 0, 1, 0]\n",
    "d['n'] = [680, 270, 204, 38, 18, 71]\n",
    "d['intercept'] = 1\n",
    "d = pd.DataFrame(np.repeat(d.values, d['n'], axis=0),   # Expanding compact data frame\n",
    "                 columns=d.columns)                     # ... keeping column names\n",
    "d = d[['intercept', 'R', 'W', 'Y']].copy()              # Dropping the n column\n",
    "n = d.shape[0]                                          # Number of observations\n",
    "\n",
    "r = np.asarray(d['R'])\n",
    "w = np.asarray(d['W'])\n",
    "y = np.asarray(d['Y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051a5724",
   "metadata": {},
   "source": [
    "### Using `delicatessen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8d92261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(theta):\n",
    "    # theta[0]: naive mean, theta[1]: sensitivity, theta[2]: specificity, theta[3]: corrected mean\n",
    "    ee_1 = r*(w - theta[0])                                                                    # EF naive mean\n",
    "    ee_2 = (1-r) * y * (w - theta[1])                                                          # EF sensitivity\n",
    "    ee_3 = (1-r) * (1-y) * ((1-w) - theta[2])                                                  # EF specificity\n",
    "    ee_4 = np.ones(y.shape[0])*theta[3]*(theta[1] + theta[2] - 1) - (theta[0] + theta[2] - 1)  # EF corrected mean\n",
    "\n",
    "    # Returning stacked estimating functions in order of parameters\n",
    "    return np.vstack([ee_1,      # EF naive mean\n",
    "                      ee_2,      # EF sensitivity\n",
    "                      ee_3,      # EF specificity\n",
    "                      ee_4])     # EF corrected mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3ba99d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mestr = MEstimator(psi, init=[0.5, 0.75, 0.75, 0.5])\n",
    "mestr.estimate(solver='lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa0eba74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: Fusion\n",
      "Uncorrected Mean: 0.716\n",
      "95% CI:           [0.687 0.744]\n",
      "Sensitivity:      0.843\n",
      "95% CI:           [0.797 0.889]\n",
      "Specificity:      0.798\n",
      "95% CI:           [0.714 0.881]\n",
      "Corrected Mean:   0.801\n",
      "95% CI:           [0.724 0.879]\n"
     ]
    }
   ],
   "source": [
    "print(\"3: Fusion\")\n",
    "print(\"Uncorrected Mean:\", np.round(mestr.theta[0], 3))\n",
    "print(\"95% CI:          \", np.round(mestr.confidence_intervals()[0, :], 3))\n",
    "print(\"Sensitivity:     \", np.round(mestr.theta[1], 3))\n",
    "print(\"95% CI:          \", np.round(mestr.confidence_intervals()[1, :], 3))\n",
    "print(\"Specificity:     \", np.round(mestr.theta[2], 3))\n",
    "print(\"95% CI:          \", np.round(mestr.confidence_intervals()[2, :], 3))\n",
    "print(\"Corrected Mean:  \", np.round(mestr.theta[3], 3))\n",
    "print(\"95% CI:          \", np.round(mestr.confidence_intervals()[3, :], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc43c6bf",
   "metadata": {},
   "source": [
    "END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
